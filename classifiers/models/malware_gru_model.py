import torch
import torch.nn as nn
import torch.nn.functional as F


class Net(nn.Module):
    def __init__(self, feature_size: int, embedding_dim: int = 5):
        super(Net, self).__init__()

        # Embedding layer for domain parts, handling missing values with a special index
        self.embedding = nn.Embedding(
            feature_size + 1, embedding_dim, padding_idx=feature_size
        )

        # 1D Convolutional layer to capture local dependencies
        self.conv1 = nn.Conv1d(embedding_dim, 64, kernel_size=5, padding=2)
        self.conv2 = nn.Conv1d(64, feature_size, kernel_size=3, padding=1)

        # GRU layer to capture long-term dependencies
        self.gru = nn.GRU(feature_size, 64, batch_first=True, bidirectional=False)

        # Fully connected layers
        self.fc1 = nn.Linear(
            64, 1024
        )  # Adjusted to accommodate bidirectional GRU output
        self.fc2 = nn.Linear(1024, 512)
        self.fc3 = nn.Linear(512, 128)
        self.fc4 = nn.Linear(128, 1)  # Output layer for binary classification

        # Dropout and Batch Normalization
        self.dropout = nn.Dropout(0.1)
        self.batchnorm1 = nn.BatchNorm1d(64)
        self.batchnorm2 = nn.BatchNorm1d(feature_size)
        self.batchnorm3 = nn.BatchNorm1d(1024)

    def forward(self, x):
        # Convert input to long if it's not already
        x = x.long()

        # Embedding input
        x = self.embedding(x)
        x = x.permute(0, 2, 1)  # Rearrange dimensions for Conv1D

        # Convolutional layers with Batch Norm and ReLU activations
        x = F.relu(self.batchnorm1(self.conv1(x)))
        x = F.relu(self.batchnorm2(self.conv2(x)))

        # GRU layer
        x, _ = self.gru(x)
        x = torch.mean(x, dim=1)  # Global average pooling over sequence

        # Fully connected layers with Dropout and Batch Norm
        x = self.dropout(F.relu(self.batchnorm3(self.fc1(x))))
        x = self.dropout(F.relu(self.fc2(x)))
        x = self.dropout(F.relu(self.fc3(x)))

        # Sigmoid activation for binary classification
        # x = torch.sigmoid(self.fc4(x))

        return self.fc4(x)
